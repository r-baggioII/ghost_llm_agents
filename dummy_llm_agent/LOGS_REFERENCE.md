# Complete Logging Reference - GHOSTS LLM Agent

This document explains **all logging** that happens in the system, from command generation to execution.

## üìÅ Log Directory Structure

```
dummy_llm_agent/
‚îú‚îÄ‚îÄ logs/                          # LLM Service logs (command generation)
‚îÇ   ‚îú‚îÄ‚îÄ command_history.jsonl     # Detailed command metadata (JSONL)
‚îÇ   ‚îú‚îÄ‚îÄ command_history.csv       # Same data in CSV format
‚îÇ   ‚îî‚îÄ‚îÄ commands_readable_*.txt   # Exported human-readable reports
‚îÇ
‚îî‚îÄ‚îÄ bin/logs/                      # GHOSTS Client logs (execution)
    ‚îú‚îÄ‚îÄ app.log                    # General application logs
    ‚îî‚îÄ‚îÄ clientupdates.log          # Client status updates
```

## 1Ô∏è‚É£ LLM Service Logs (Command Generation)

### Location
`logs/command_history.jsonl` and `logs/command_history.csv`

### What's Logged
**When**: Every time the LLM service generates a command  
**Where**: `llm_service.py` writes to both files

### Example Entry (JSONL)
```json
{
  "timestamp": "2025-01-10T14:23:45.123456",
  "npc_name": "Dr. Sarah Chen",
  "npc_role": "AI Research Scientist",
  "command": "cd /home/rocio/Documentos/GHOSTS/dummy_llm_agent/workspace && mkdir -p data/experiments && echo 'Starting experiment' > data/experiments/notes.txt",
  "working_directory": "/home/rocio/Documentos/GHOSTS/dummy_llm_agent/workspace",
  "delay_after": 15,
  "llm_model": "gpt-4o-mini",
  "session_id": "20250110"
}
```

### What This Tells You
- ‚úÖ **What command** was generated by the AI
- ‚úÖ **When** it was generated (exact timestamp)
- ‚úÖ **Which NPC** generated it
- ‚úÖ **Where** it will run (working directory)
- ‚úÖ **How long** to wait after execution

### What This DOESN'T Tell You
- ‚ùå Whether the command actually executed
- ‚ùå What the output was (stdout/stderr)
- ‚ùå If it succeeded or failed (exit code)
- ‚ùå What files were actually created/modified

## 2Ô∏è‚É£ GHOSTS Client Logs (Execution)

### Location
`bin/logs/app.log` and `bin/logs/clientupdates.log`

### app.log

**What's Logged**: General GHOSTS client activity

**Example content:**
```
2025-01-10 14:23:45.678|INFO|Ghosts.Client.Universal.Program|Starting GHOSTS Universal Client v8.0.0
2025-01-10 14:23:46.123|INFO|Ghosts.Domain.Code.Timeline.TimelineManager|Timeline loaded successfully
2025-01-10 14:23:46.456|INFO|Ghosts.Client.Universal.Handlers.BashHandler|Executing command: cd /home/rocio/Documentos/GHOSTS/dummy_llm_agent/workspace && ls -la
2025-01-10 14:23:46.789|INFO|Ghosts.Client.Universal.Handlers.BashHandler|Command completed with exit code 0
```

**What This Tells You:**
- ‚úÖ When commands were **actually executed** (not just generated)
- ‚úÖ Handler activity (BashHandler, etc.)
- ‚úÖ Timeline processing events
- ‚úÖ Client lifecycle (startup, shutdown)
- ‚úÖ Exit codes (success/failure)

### clientupdates.log

**What's Logged**: Client health checks and status updates to API

**Example content:**
```
2025-01-10 14:23:50.123|INFO|Ghosts.Client.Universal.Comms.Updates|Sending health check to API
2025-01-10 14:23:50.456|INFO|Ghosts.Client.Universal.Comms.Updates|Health check successful
```

**What This Tells You:**
- ‚úÖ Communication with GHOSTS API (if configured)
- ‚úÖ Client health status
- ‚úÖ Network connectivity

### How to View GHOSTS Client Logs

```bash
# Watch app.log in real-time
tail -f bin/logs/app.log

# View recent errors
grep ERROR bin/logs/app.log

# View command executions only
grep "Executing command" bin/logs/app.log

# View with timestamps from last hour
grep "$(date '+%Y-%m-%d %H:')" bin/logs/app.log
```

## üîó Correlation: Generation ‚Üí Execution

To track a command from generation to execution:

### 1. Find generated command in LLM logs
```bash
# Get latest command from LLM service
LAST_CMD=$(tail -n1 logs/command_history.jsonl | jq -r '.command')
echo "Looking for: $LAST_CMD"
```

### 2. Find execution in GHOSTS logs
```bash
# Search for it in app.log
grep "$LAST_CMD" bin/logs/app.log
```

### Example Workflow

```bash
# 1. LLM generates command at 14:23:45.123
# logs/command_history.jsonl:
# {"timestamp":"2025-01-10T14:23:45.123456","command":"ls -la",...}

# 2. Timeline delivers it to BashHandler ~15 seconds later
# bin/logs/app.log:
# 2025-01-10 14:24:00.456|INFO|...|Executing command: cd ... && ls -la

# 3. Command completes
# bin/logs/app.log:
# 2025-01-10 14:24:00.789|INFO|...|Command completed with exit code 0
```

## üïê Time Calculations

### Time Between Command Generations

**From LLM logs** (`logs/command_history.jsonl`):

```bash
# Python script to calculate deltas
python3 << 'EOF'
import json
from datetime import datetime

commands = []
with open('logs/command_history.jsonl', 'r') as f:
    for line in f:
        commands.append(json.loads(line))

for i in range(1, len(commands)):
    prev = datetime.fromisoformat(commands[i-1]['timestamp'])
    curr = datetime.fromisoformat(commands[i]['timestamp'])
    delta = (curr - prev).total_seconds()
    print(f"{delta:.1f}s between commands")
EOF
```

### Time Between Command Executions

**From GHOSTS logs** (`bin/logs/app.log`):

```bash
# Extract execution timestamps
grep "Executing command" bin/logs/app.log | \
  awk -F'|' '{print $1}' | \
  while read -r line; do 
    date -d "$line" +%s
  done | \
  awk 'NR>1 {print $1-prev} {prev=$1}'
```

## üìä Complete Monitoring Setup

### Terminal 1: LLM Command Generation
```bash
./view-logs.sh tail
```

### Terminal 2: GHOSTS Command Execution
```bash
tail -f bin/logs/app.log | grep "Executing command"
```

### Terminal 3: Statistics Dashboard
```bash
watch -n 5 './view-logs.sh stats'
```

### Terminal 4: LLM Service Status
```bash
# Check if service is running and responsive
watch -n 10 'curl -s http://localhost:5555/status | jq .'
```

## üîç Debugging Scenarios

### Command was generated but never executed

**Check:**
1. Is GHOSTS client running? `ps aux | grep Ghosts`
2. Check app.log for errors: `grep ERROR bin/logs/app.log`
3. Verify timeline is active: `grep Timeline bin/logs/app.log`

### Command executed but with wrong directory

**Check:**
1. Timeline configuration in `config/timeline.json`
2. Verify `working_directory` in command log matches expected path

### LLM service not generating commands

**Check:**
1. Is Flask running? `ps aux | grep llm_service`
2. Check for Python errors: `journalctl -u llm-service` (if systemd)
3. Test manually: `curl http://localhost:5555/next-command`

### Too many/few commands being executed

**Check:**
1. Timeline `delay_after` setting in `config/timeline.json`
2. Count rate: `wc -l logs/command_history.jsonl` (should increase ~4/min with 15s delay)

## üìà Log Analysis Examples

### Commands Per Hour
```bash
jq -r '.timestamp | split("T")[1] | split(":")[0]' logs/command_history.jsonl | \
  sort | uniq -c
```

### Most Active NPC
```bash
jq -r '.npc_name' logs/command_history.jsonl | sort | uniq -c | sort -rn
```

### Average Delay Between Commands (Expected: ~15s)
```bash
python3 << 'EOF'
import json
from datetime import datetime

deltas = []
with open('logs/command_history.jsonl', 'r') as f:
    lines = [json.loads(line) for line in f]
    
for i in range(1, len(lines)):
    prev = datetime.fromisoformat(lines[i-1]['timestamp'])
    curr = datetime.fromisoformat(lines[i]['timestamp'])
    deltas.append((curr - prev).total_seconds())

if deltas:
    avg = sum(deltas) / len(deltas)
    print(f"Average: {avg:.1f}s")
    print(f"Min: {min(deltas):.1f}s")
    print(f"Max: {max(deltas):.1f}s")
EOF
```

### File Operations Over Time
```bash
jq -r 'select(.command | test("touch|mkdir|echo.*>")) | 
  "\(.timestamp) | \(.command)"' logs/command_history.jsonl
```

## üóÇÔ∏è Log Retention

### Current Setup
- **No automatic rotation** - logs grow indefinitely
- **Manual management** recommended

### Recommended Strategy

**Daily Archives** (keep last 30 days):
```bash
# Archive yesterday's commands
YESTERDAY=$(date -d yesterday +%Y%m%d)
jq "select(.session_id == \"$YESTERDAY\")" logs/command_history.jsonl \
  > logs/archive/commands_$YESTERDAY.jsonl
```

**Weekly Cleanup**:
```bash
# Keep last 7 days in main log
WEEK_AGO=$(date -d '7 days ago' --iso-8601=seconds)
jq "select(.timestamp > \"$WEEK_AGO\")" logs/command_history.jsonl \
  > logs/command_history_temp.jsonl
mv logs/command_history_temp.jsonl logs/command_history.jsonl
```

### Disk Space Monitoring
```bash
# Check log sizes
du -sh logs/
du -sh bin/logs/

# Monitor growth rate
watch -n 60 'du -h logs/command_history.jsonl'
```

## üö® Important Notes

1. **LLM logs ‚â† Execution logs**
   - LLM logs show what was **planned**
   - GHOSTS logs show what was **done**

2. **Timestamps are in local timezone**
   - LLM service uses Python's `datetime.now()`
   - GHOSTS client uses system time
   - For UTC, modify llm_service.py to use `datetime.utcnow()`

3. **Command logs don't include output**
   - To capture stdout/stderr, modify BashHandler
   - Or use `script` command to record terminal sessions

4. **Session IDs reset daily**
   - Format: YYYYMMDD (e.g., `20250110`)
   - Use for grouping daily activity

5. **Logs survive restarts**
   - Append-only, never overwritten
   - Safe to restart client/service without losing history

## üîß Advanced: Custom Logging

### Add execution results to LLM logs

Modify timeline to capture output:
```json
{
  "Command": "bash",
  "CommandArgs": [
    "-c",
    "RESULT=$(curl -s http://localhost:5555/next-command | jq -r .command); eval \"$RESULT\" 2>&1 | tee -a logs/execution_output.log"
  ]
}
```

### Forward logs to external system

**To Elasticsearch:**
```bash
tail -f logs/command_history.jsonl | \
  while read line; do
    curl -X POST "http://elastic:9200/ghosts/_doc" \
      -H 'Content-Type: application/json' \
      -d "$line"
  done
```

**To Splunk:**
```bash
tail -f logs/command_history.jsonl | \
  nc splunk-host 514  # Syslog
```

---

**See also:**
- [LOGGING.md](LOGGING.md) - LLM command log analysis
- [README.md](README.md) - General documentation
- [QUICKSTART.md](QUICKSTART.md) - Getting started guide
